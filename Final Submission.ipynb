{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2719\n",
      "636\n"
     ]
    }
   ],
   "source": [
    "wordset = set()\n",
    "wordlist = []\n",
    "for i in df.message:\n",
    "    wordset = wordset.union(word for word in i.split(\" \")) # creating set of all words in the dataset\n",
    "    wordlist += i.split(\" \") # creating list of all words in the dataset to include frequency of each word\n",
    "print(len(wordlist))\n",
    "print(len(wordset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to group words with at most 2 different letters\n",
    "def group_similar_words(words,score):\n",
    "    grouped_words = defaultdict(list) # We use defaultdict to avoid key errors when adding values to the dictionary.\n",
    "    used = set()\n",
    "    \n",
    "    for word1, word2 in combinations(words, 2):\n",
    "        distance = Levenshtein.hamming(word1, word2)\n",
    "        if distance <= 1 and len(word1) == len(word2):\n",
    "            if word1 not in used and word2 not in used:\n",
    "                grouped_words[word1].append(word2) # grouped_words[word1] will automatically create an empty list (due to defaultdict) if word1 does not already exist in the dictionary.\n",
    "                used.add(word2)\n",
    "\n",
    "    return grouped_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_wordlist = []\n",
    "for i in pd.DataFrame(wordlist).value_counts().keys(): # sorting words by frequency\n",
    "    ordered_wordlist.append(i[0]) # i is a tuple, i[0] is the word\n",
    "len(ordered_wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'terranix': ['tprranix', 'terramix', 'tekranix', 'tehranix'], 'sirenix': ['surenix', 'sirtnix', 'sirepix', 'airenix'], 'pluvia': ['pldvia'], 'ragex': ['ragux', 'rages', 'ragbx'], 'solarix': ['solarrx', 'solariy', 'solarih'], 'nebuz': ['qebuz', 'nebzz', 'ncbuz', 'neguz', 'nxbuz', 'yebuz'], 'quasar': ['qualar', 'qudsar'], 'gryphox': ['grypyox', 'grbphox', 'gryohox', 'gryphod', 'gryphov', 'gryphpx'], 'faerix': ['faemix', 'faerkx', 'faeyix', 'fjerix'], 'astron': ['ustron', 'asbron', 'aslron', 'astrln', 'astrob', 'astroh', 'astrrn'], 'nebulax': ['nebusax', 'nebuoax', 'nebulyx', 'nebulix', 'nebuhax', 'nxbulax', 'nibulax', 'ngbulax', 'febulax'], 'floraz': ['floran', 'fboraz', 'florgz', 'floraj'], 'cosmix': ['yosmix', 'cofmix', 'cosmia', 'cosmpx', 'hosmix'], 'vortex': ['vcrtex', 'voutex', 'vorcex', 'dortex'], 'cryptoz': ['crqptoz', 'cryftoz', 'crypooz', 'chyptoz'], 'pollex': ['pallex'], 'celestar': ['cehestar', 'celejtar', 'celistar', 'celwstar', 'cewestar', 'czlestar', 'ceaestar'], 'herox': ['herux', 'heyox', 'heeox'], 'novum': ['novtm', 'iovum'], 'lazeron': ['vazeron', 'lazxron', 'lazervn', 'lazerqn', 'lazerom', 'fazeron'], 'quantix': ['quagtix', 'quansix'], 'quantaz': ['quanaaz', 'qulntaz', 'quaztaz', 'quanyaz', 'quantay'], 'virtua': ['virtud'], 'shamex': ['jhamex', 'ghamex'], 'pulsar': ['puxsar', 'pzlsar', 'pulaar'], 'glixx': ['gyixx', 'glcxx', 'ghixx'], 'ventus': ['yentus'], 'fearix': ['fearjx', 'febrix', 'flarix', 'ferrix'], 'robonix': ['tobonix', 'yobonix', 'robonis', 'roboqix', 'robonib', 'robdnix'], 'ufox': ['qfox', 'ueox', 'ufoi', 'ufow', 'uhox', 'uxox'], 'calmox': ['cqlmox', 'calmoa', 'cacmox'], 'awezom': ['owezom', 'awozom', 'awezox', 'awezon'], 'joyzor': ['boyzor', 'jpyzor', 'jlyzor'], 'warpz': ['warpu', 'wanpz'], 'shockus': ['sqockus', 'shockbs', 'shockws', 'shockss'], 'anxius': ['anzius', 'anxiuz', 'anxims', 'anxids', 'aneius'], 'novax': ['novwx', 'novgx', 'norax', 'nomax', 'nokax', 'sovax'], 'orbitaz': ['oxbitaz', 'ornitaz', 'orbitzz', 'orbitay', 'orbitam', 'odbitaz'], 'dredax': ['dredai', 'dredzx', 'dreeax', 'dreiax', 'duedax'], 'neuraz': ['neulaz', 'nzuraz'], 'unikor': ['znikor', 'xnikor'], 'aeon': ['acon', 'ueon', 'weon', 'akon', 'aeqn', 'aeop'], 'rootix': ['rookix', 'roltix', 'riotix', 'dootix'], 'herba': ['nerba', 'herbw', 'hfrba', 'hzrba'], 'stardux': ['rtardux', 'svardux', 'stnrdux', 'stjrdux', 'etardux'], 'faunar': ['haunar', 'xaunar', 'fsunar'], 'galaxum': ['zalaxum', 'ialaxum', 'gmlaxum', 'galaxuw', 'galaxym'], 'pridius': ['vridius', 'przdius', 'pridiuo', 'pridiun', 'cridius'], 'titanos': ['titayos', 'titanor', 'tetanos', 'bitanos'], 'empathix': ['empnthix', 'empathtx'], 'elvex': ['euvex', 'elwex', 'elqex', 'ebvex'], 'petros': ['pesros'], 'gaiax': ['yaiax', 'gniax', 'gaisx', 'gaial', 'gaikx', 'gayax', 'gjiax'], 'biomar': ['biumar', 'biomvr', 'biompr'], 'blissam': ['bliskam', 'blessam', 'bliisam', 'blisqam', 'blissac', 'blissxm', 'blnssam', 'bgissam', 'bdissam'], 'kometa': ['kkmeta', 'kometr', 'kometo', 'kometk'], 'excitar': ['kxcitar', 'jxcitar', 'excitav', 'excvtar'], 'luvium': ['luzium', 'lrvium', 'lumium', 'luvgum'], 'mechan': ['mechun', 'zechan', 'hechan'], 'leafon': ['leaion', 'ieafon', 'leffon', 'lehfon', 'leofon'], 'xeno': ['xenn', 'xenl', 'xene', 'eeno'], 'zenox': ['zeqox', 'zenrx', 'zenow', 'venox', 'cenox', 'lenox'], 'nanobyt': ['oanobyt', 'nunobyt'], 'ekstax': ['ekstox', 'ekstdx', 'ekltax'], 'circux': ['nircux', 'yircux', 'cixcux', 'civcux', 'ciwcux', 'circum', 'chrcux'], 'dronix': ['oronix', 'wronix', 'drosix', 'djonix', 'droeix'], 'hopium': ['mopium', 'hopipm', 'hopjum', 'fopium'], 'goblax': ['coblax', 'aoblax', 'gobqax', 'gmblax', 'gobfax', 'goblam', 'goblex', 'goilax'], 'cyclopix': ['cycvopix', 'cycbopix'], 'fenix': ['cenix', 'tenix', 'fefix', 'fenii', 'feyix', 'fenwx', 'fenpx', 'feniy'], 'datax': ['dawax', 'datxx', 'dataz', 'datas', 'dajax'], 'angstix': ['annstix', 'angxtix', 'angstox', 'angstic', 'angsqix', 'afgstix'], 'codex': ['modex', 'cosex', 'codeu', 'cydex'], 'magix': ['mzgix', 'malix', 'magit'], 'nimbus': ['oimbus', 'nimbub', 'nikbus', 'cimbus'], 'arbor': ['arbsr', 'arbon', 'arcor'], 'ekos': ['tkos'], 'deitax': ['dpitax', 'deitzx', 'deirax', 'deftax'], 'mermax': ['mormax', 'mermav', 'mermal'], 'sadix': ['sasix', 'sapix', 'sadpx', 'sudix'], 'synapz': ['syuapz', 'synapx', 'synajz', 'synafz', 'synadz'], 'relikum': ['rnlikum', 'reljkum', 'relikzm'], 'biotex': ['biorex', 'biokex'], 'cybron': ['cybfon', 'cybroi', 'cbbron', 'dybron'], 'fabulon': ['faoulon', 'ftbulon', 'gabulon'], 'euphorix': ['euphorgx', 'euphorim', 'euphorsx', 'egphorix'], 'sorrowz': ['soyrowz', 'sorrowa'], 'pulsox': ['pulson', 'puksox', 'pulsoo', 'pulsoh', 'puqsox', 'pclsox'], 'solux': ['selux', 'sorux', 'soluz', 'solix', 'solax', 'sllux'], 'algorix': ['algorid'], 'aquos': ['zquos', 'aqjos', 'aqpos', 'aquoe', 'aquon'], 'nympha': ['nymphb', 'nydpha'], 'epikoz': ['epikot', 'epikiz', 'epgkoz', 'eiikoz'], 'meteorn': ['metlorn', 'meteokn', 'meteoen', 'mefeorn'], 'zorp': ['zorf', 'zolp', 'corp', 'horp', 'zyrp'], 'novara': ['movara', 'novarr', 'novafa', 'nivara'], 'digitron': ['digitvon', 'digitrtn', 'digitrop'], 'aviana': ['ariana', 'aviaia', 'akiana', 'avcana', 'avisna', 'aviyna'], 'mythox': ['mythxx', 'mytqox', 'mythjx', 'mymhox', 'eythox'], 'terram': ['terrrm', 'terrnm', 'terpam', 'terkam'], 'insectus': ['onsectus', 'insestus', 'insfctus', 'izsectus'], 'technos': ['tvchnos', 'tkchnos', 'technoc', 'technds', 'tecfnos', 'tecanos', 'sechnos'], 'trustix': ['nrustix', 'tqustix', 'truotix', 'trusqix', 'trusuix', 'truztix', 'tbustix'], 'cybrex': ['cebrex', 'chbrex', 'cybdex', 'cybrpx', 'cywrex'], 'drakos': ['krakos', 'rrakos', 'dmakos', 'draaos', 'ddakos', 'dbakos'], 'holox': ['holxx', 'hollx', 'holsx'], 'sagax': ['sagsx', 'sagmx', 'sagav', 'sagau', 'sagaq', 'sagaa'], 'zephyr': ['mephyr', 'zgphyr', 'fephyr'], 'lunox': ['lunbx', 'lunnx', 'lunol', 'lunrx', 'junox'], 'beastix': ['blastix', 'beasxix', 'beastpx', 'beastit', 'beastij', 'beadtix'], 'disgux': ['disgub', 'disgue', 'disvux', 'dtsgux'], 'nanozom': ['nawozom', 'nantzom', 'nanozod', 'nanocom'], 'nexus': ['qexus', 'nexhs', 'vexus'], 'seepod': ['seypod', 'seepos', 'seepoa', 'beepod'], 'sporzom': ['sponzom', 'sporzlm', 'sporpom', 'sporlom'], 'furio': ['kurio', 'furix'], 'lorix': ['worix', 'corix', 'lsrix', 'ltrix'], 'blapoz': ['ulapoz', 'blaloz', 'blapnz', 'blatoz', 'bqapoz', 'bvapoz'], 'legax': ['eegax'], 'foliar': ['folwar', 'folnar', 'folixr', 'fobiar'], 'centarex': ['centarea', 'centarer', 'centarkx', 'centarnx'], 'gleex': ['gpeex', 'gleek', 'gleed', 'gleea', 'geeex'], 'techix': ['techip', 'techih'], 'kmakos': ['kzakos', 'kgakos'], 'floxan': ['flodan']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_ordered_words = dict(group_similar_words(ordered_wordlist,2))\n",
    "print(grouped_ordered_words)\n",
    "len(grouped_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, word_dict):\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    \n",
    "    # Iterate through each word in the text\n",
    "    for word in words:\n",
    "        replaced = False\n",
    "        # Check each key-value pair in the dictionary\n",
    "        for key, synonyms in word_dict.items():\n",
    "            if word in synonyms:\n",
    "                result.append(key)  # Replace word with the dictionary key\n",
    "                replaced = True\n",
    "                break\n",
    "        if not replaced:\n",
    "            result.append(word)  # If no replacement found, keep the original word\n",
    "    \n",
    "    # Join the result back into a string\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astron novum quasar glixx\n",
      "asbron novum quasar glixx\n"
     ]
    }
   ],
   "source": [
    "print(replace_words(df.message[69],grouped_ordered_words))\n",
    "print(df.message[69])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see how the data is changing after each step of the replacement of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df.message)):\n",
    "    df.loc[i,\"message\"] = replace_words(df.message[i],grouped_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>fingers</th>\n",
       "      <th>tail</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pluvia arbor aquos</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>Aquari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmix xeno nebuz orbitaz</td>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>Zorblax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solarix glixx novum galaxum quasar</td>\n",
       "      <td>5</td>\n",
       "      <td>yes</td>\n",
       "      <td>Zorblax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arbor insectus petros ekos rootix nimbus</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>Florian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mermax drakos lorix epikoz deitax</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "      <td>Faerix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    message  fingers tail  species\n",
       "0                        pluvia arbor aquos        4   no   Aquari\n",
       "1                 cosmix xeno nebuz orbitaz        5  yes  Zorblax\n",
       "2        solarix glixx novum galaxum quasar        5  yes  Zorblax\n",
       "3  arbor insectus petros ekos rootix nimbus        2  yes  Florian\n",
       "4         mermax drakos lorix epikoz deitax        4   no   Faerix"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)  # Set sparse_output=False to return a dense array\n",
    "\n",
    "encoded_tail = encoder.fit_transform(df[['tail']])\n",
    "\n",
    "encoded_tail_df = pd.DataFrame(encoded_tail, columns=encoder.get_feature_names_out(['tail']))\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "df = pd.concat([df, encoded_tail_df], axis=1).drop('tail', axis=1)  # Optionally drop original 'tail' column\n",
    "df.drop([\"tail_no\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>fingers</th>\n",
       "      <th>species</th>\n",
       "      <th>tail_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pluvia arbor aquos</td>\n",
       "      <td>4</td>\n",
       "      <td>Aquari</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmix xeno nebuz orbitaz</td>\n",
       "      <td>5</td>\n",
       "      <td>Zorblax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solarix glixx novum galaxum quasar</td>\n",
       "      <td>5</td>\n",
       "      <td>Zorblax</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arbor insectus petros ekos rootix nimbus</td>\n",
       "      <td>2</td>\n",
       "      <td>Florian</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mermax drakos lorix epikoz deitax</td>\n",
       "      <td>4</td>\n",
       "      <td>Faerix</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    message  fingers  species  tail_yes\n",
       "0                        pluvia arbor aquos        4   Aquari       0.0\n",
       "1                 cosmix xeno nebuz orbitaz        5  Zorblax       1.0\n",
       "2        solarix glixx novum galaxum quasar        5  Zorblax       1.0\n",
       "3  arbor insectus petros ekos rootix nimbus        2  Florian       1.0\n",
       "4         mermax drakos lorix epikoz deitax        4   Faerix       0.0"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>fingers</th>\n",
       "      <th>species</th>\n",
       "      <th>tail_yes</th>\n",
       "      <th>Message_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pluvia arbor aquos</td>\n",
       "      <td>4</td>\n",
       "      <td>Aquari</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[pluvia, arbor, aquos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosmix xeno nebuz orbitaz</td>\n",
       "      <td>5</td>\n",
       "      <td>Zorblax</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[cosmix, xeno, nebuz, orbitaz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>solarix glixx novum galaxum quasar</td>\n",
       "      <td>5</td>\n",
       "      <td>Zorblax</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[solarix, glixx, novum, galaxum, quasar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arbor insectus petros ekos rootix nimbus</td>\n",
       "      <td>2</td>\n",
       "      <td>Florian</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[arbor, insectus, petros, ekos, rootix, nimbus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mermax drakos lorix epikoz deitax</td>\n",
       "      <td>4</td>\n",
       "      <td>Faerix</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[mermax, drakos, lorix, epikoz, deitax]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    message  fingers  species  tail_yes  \\\n",
       "0                        pluvia arbor aquos        4   Aquari       0.0   \n",
       "1                 cosmix xeno nebuz orbitaz        5  Zorblax       1.0   \n",
       "2        solarix glixx novum galaxum quasar        5  Zorblax       1.0   \n",
       "3  arbor insectus petros ekos rootix nimbus        2  Florian       1.0   \n",
       "4         mermax drakos lorix epikoz deitax        4   Faerix       0.0   \n",
       "\n",
       "                                    Message_Tokens  \n",
       "0                           [pluvia, arbor, aquos]  \n",
       "1                   [cosmix, xeno, nebuz, orbitaz]  \n",
       "2         [solarix, glixx, novum, galaxum, quasar]  \n",
       "3  [arbor, insectus, petros, ekos, rootix, nimbus]  \n",
       "4          [mermax, drakos, lorix, epikoz, deitax]  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Message_Tokens'] = df['message'].apply(lambda x: x.split())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Word2Vec to convert words into vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19521, 40785)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences=df['Message_Tokens'],   # Tokenized messages\n",
    "    vector_size=20,                   # Word vector size (20 dimensions)\n",
    "    window=3,                         # Context window size\n",
    "    min_count=1,                      # Include all words (min frequency = 1)\n",
    "    sg=0,                             # Use CBOW (faster for smaller data)\n",
    ")\n",
    "\n",
    "# Train the Word2Vec model on the messages\n",
    "w2v_model.train(df['Message_Tokens'], total_examples=len(df['Message_Tokens']), epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 20)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_vector(tokens, model):\n",
    "    # If a token is in the model's vocabulary, get its vector; otherwise, ignore it\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)  # Return a zero vector if no words are found\n",
    "    else:\n",
    "        return np.mean(vectors, axis=0)  # Average the word vectors to get the sentence vector\n",
    "\n",
    "\n",
    "X_text = np.array(df['Message_Tokens'].apply(lambda tokens: sentence_vector(tokens, w2v_model)).tolist())\n",
    "X_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_text is an array where each row is the averaged vector representation of an alien message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 22)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fingers = df['fingers'].values.reshape(-1, 1)\n",
    "X_tail = df['tail_yes'].values.reshape(-1, 1)\n",
    "\n",
    "# Combine all features (Text, Number of Fingers, Tail)\n",
    "X = np.hstack([X_text, X_fingers, X_tail])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define target (Species)\n",
    "y = df['species']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72     Emotivor\n",
       "182     Quixnar\n",
       "131     Zorblax\n",
       "410     Florian\n",
       "193     Florian\n",
       "         ...   \n",
       "106     Quixnar\n",
       "270    Emotivor\n",
       "348     Zorblax\n",
       "435     Florian\n",
       "102     Sentire\n",
       "Name: species, Length: 450, dtype: object"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the target variable\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 7, 9, 4, 4, 5, 7, 6, 2, 7, 6, 7, 4, 1, 3, 1, 8, 5, 3, 6, 0, 4,\n",
       "       2, 9, 5, 4, 5, 9, 1, 3, 8, 7, 7, 4, 6, 7, 9, 3, 9, 1, 2, 0, 8, 7,\n",
       "       7, 1, 7, 7, 1, 5, 4, 7, 4, 2, 8, 0, 2, 9, 8, 7, 0, 1, 6, 8, 4, 3,\n",
       "       2, 4, 5, 6, 2, 6, 7, 4, 2, 9, 2, 1, 2, 3, 8, 7, 9, 7, 2, 8, 6, 5,\n",
       "       0, 6, 9, 0, 1, 1, 4, 8, 0, 0, 5, 1, 6, 7, 6, 4, 2, 7, 4, 4, 1, 3,\n",
       "       2, 4, 0, 6, 7, 1, 7, 5, 3, 8, 8, 9, 3, 2, 3, 9, 9, 3, 7, 3, 2, 6,\n",
       "       7, 5, 7, 0, 8, 4, 0, 8, 2, 9, 8, 3, 3, 3, 5, 7, 4, 6, 8, 0, 2, 5,\n",
       "       6, 5, 9, 5, 5, 0, 6, 1, 1, 2, 9, 9, 4, 9, 6, 1, 5, 3, 2, 9, 1, 0,\n",
       "       7, 0, 8, 2, 8, 0, 9, 6, 4, 5, 5, 1, 2, 1, 5, 7, 7, 2, 4, 9, 9, 9,\n",
       "       2, 1, 4, 2, 5, 2, 1, 9, 7, 8, 7, 7, 0, 7, 1, 6, 1, 5, 1, 2, 1, 9,\n",
       "       2, 4, 9, 0, 6, 5, 2, 5, 4, 7, 1, 0, 5, 1, 4, 9, 4, 6, 0, 6, 6, 0,\n",
       "       1, 7, 6, 8, 8, 4, 8, 5, 9, 3, 7, 7, 2, 1, 5, 9, 2, 7, 5, 5, 4, 4,\n",
       "       2, 8, 7, 1, 0, 0, 1, 3, 4, 2, 4, 0, 5, 7, 2, 5, 3, 6, 6, 6, 2, 5,\n",
       "       5, 3, 2, 9, 3, 5, 1, 8, 1, 2, 4, 4, 3, 8, 4, 3, 3, 2, 0, 5, 9, 1,\n",
       "       6, 4, 6, 8, 7, 1, 1, 6, 0, 2, 9, 5, 7, 7, 9, 6, 7, 7, 0, 6, 6, 4,\n",
       "       5, 3, 2, 4, 6, 8, 6, 6, 1, 5, 7, 7, 7, 1, 3, 0, 0, 6, 3, 1, 3, 7,\n",
       "       4, 5, 0, 2, 4, 4, 8, 7, 6, 0, 2, 0, 0, 6, 4, 4, 0, 4, 9, 2, 2, 0,\n",
       "       5, 7, 8, 9, 0, 0, 4, 9, 7, 9, 9, 1, 0, 8, 4, 3, 8, 8, 9, 9, 1, 1,\n",
       "       1, 0, 1, 5, 8, 1, 8, 7, 0, 0, 9, 4, 7, 3, 3, 7, 9, 5, 3, 1, 7, 2,\n",
       "       4, 3, 7, 5, 0, 5, 0, 6, 5, 0, 2, 2, 8, 2, 0, 1, 0, 1, 9, 8, 8, 1,\n",
       "       2, 5, 8, 7, 4, 7, 2, 9, 4, 8])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-26 {color: black;}#sk-container-id-26 pre{padding: 0;}#sk-container-id-26 div.sk-toggleable {background-color: white;}#sk-container-id-26 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-26 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-26 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-26 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-26 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-26 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-26 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-26 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-26 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-26 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-26 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-26 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-26 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-26 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-26 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-26 div.sk-item {position: relative;z-index: 1;}#sk-container-id-26 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-26 div.sk-item::before, #sk-container-id-26 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-26 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-26 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-26 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-26 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-26 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-26 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-26 div.sk-label-container {text-align: center;}#sk-container-id-26 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-26 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-26\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=25, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=25, gamma=&#x27;auto&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=25, gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svm.SVC(kernel='linear', C=25,gamma='auto')\n",
    "model.fit(X_train, y_train_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordset_test = set()\n",
    "wordlist_test = []\n",
    "for i in x_test_df.message:\n",
    "    wordset_test = wordset_test.union(word for word in i.split(\" \"))\n",
    "    wordlist_test += i.split(\" \")\n",
    "len(wordset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(text, word_dict):\n",
    "    words = text.split()\n",
    "    result = []\n",
    "    \n",
    "    # Iterate through each word in the text\n",
    "    for word in words:\n",
    "        replaced = False\n",
    "        # Check each key-value pair in the dictionary\n",
    "        for key in word_dict.keys():\n",
    "            if Levenshtein.hamming(word, key) <= 1 and len(word) == len(key):\n",
    "                result.append(key)  # Replace word with the dictionary key\n",
    "                replaced = True\n",
    "                break\n",
    "        if not replaced:\n",
    "            result.append(word)  # If no replacement found, keep the original word\n",
    "    \n",
    "    # Join the result back into a string\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_test_df.message)):\n",
    "    x_test_df.loc[i,\"message\"] = replace_words(x_test_df.message[i],grouped_ordered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordset_test = set()\n",
    "wordlist_test = []\n",
    "for i in x_test_df.message:\n",
    "    wordset_test = wordset_test.union(word for word in i.split(\" \"))\n",
    "    wordlist_test += i.split(\" \")\n",
    "len(wordset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse_output=False)  # Set sparse_output=False to return a dense array\n",
    "\n",
    "encoded_tail_test = encoder.fit_transform(x_test_df[['tail']])\n",
    "\n",
    "encoded_tail_df_test = pd.DataFrame(encoded_tail_test, columns=encoder.get_feature_names_out(['tail']))\n",
    "\n",
    "# Concatenate the original DataFrame with the one-hot encoded DataFrame\n",
    "df_test = pd.concat([x_test_df, encoded_tail_df_test], axis=1).drop('tail', axis=1)  # Optionally drop original 'tail' column\n",
    "df_test.drop([\"tail_no\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>fingers</th>\n",
       "      <th>tail_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zephyr terram nimbus terram faunar foliar</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joyzor gleex luvium calmox shockus blissam</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aquos arbor ventus</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nympha nympha epikoz nympha mythox mythox mythox</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deitax sirenix fabulon</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            message  fingers  tail_yes\n",
       "0         zephyr terram nimbus terram faunar foliar        2       0.0\n",
       "1        joyzor gleex luvium calmox shockus blissam        4       1.0\n",
       "2                                aquos arbor ventus        4       1.0\n",
       "3  nympha nympha epikoz nympha mythox mythox mythox        3       0.0\n",
       "4                            deitax sirenix fabulon        4       1.0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>fingers</th>\n",
       "      <th>tail_yes</th>\n",
       "      <th>Message_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zephyr terram nimbus terram faunar foliar</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[zephyr, terram, nimbus, terram, faunar, foliar]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>joyzor gleex luvium calmox shockus blissam</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[joyzor, gleex, luvium, calmox, shockus, blissam]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aquos arbor ventus</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[aquos, arbor, ventus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nympha nympha epikoz nympha mythox mythox mythox</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[nympha, nympha, epikoz, nympha, mythox, mytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deitax sirenix fabulon</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[deitax, sirenix, fabulon]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            message  fingers  tail_yes  \\\n",
       "0         zephyr terram nimbus terram faunar foliar        2       0.0   \n",
       "1        joyzor gleex luvium calmox shockus blissam        4       1.0   \n",
       "2                                aquos arbor ventus        4       1.0   \n",
       "3  nympha nympha epikoz nympha mythox mythox mythox        3       0.0   \n",
       "4                            deitax sirenix fabulon        4       1.0   \n",
       "\n",
       "                                      Message_Tokens  \n",
       "0   [zephyr, terram, nimbus, terram, faunar, foliar]  \n",
       "1  [joyzor, gleex, luvium, calmox, shockus, blissam]  \n",
       "2                             [aquos, arbor, ventus]  \n",
       "3  [nympha, nympha, epikoz, nympha, mythox, mytho...  \n",
       "4                         [deitax, sirenix, fabulon]  "
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Message_Tokens'] = df_test['message'].apply(lambda x: x.split())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_test = np.array(df_test['Message_Tokens'].apply(lambda tokens: sentence_vector(tokens, w2v_model)).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 20)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fingers_test = df_test['fingers'].values.reshape(-1, 1)\n",
    "X_tail_test = df_test['tail_yes'].values.reshape(-1, 1)\n",
    "\n",
    "# Combine all features (Text, Number of Fingers, Tail)\n",
    "X_test = np.hstack([X_text_test, X_fingers_test, X_tail_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test_species = label_encoder.inverse_transform(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aquari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Florian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Faerix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mythron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Mythron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Nexoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Mythron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Quixnar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Emotivor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      species\n",
       "0      Aquari\n",
       "1     Sentire\n",
       "2     Florian\n",
       "3      Faerix\n",
       "4     Mythron\n",
       "..        ...\n",
       "294   Mythron\n",
       "295    Nexoon\n",
       "296   Mythron\n",
       "297   Quixnar\n",
       "298  Emotivor\n",
       "\n",
       "[299 rows x 1 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions = pd.DataFrame(y_pred_test_species, columns=['species'])\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to 'svm_predictions.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_predictions.to_csv('svm_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'svm_predictions.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
